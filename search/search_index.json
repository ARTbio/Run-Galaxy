{
    "docs": [
        {
            "location": "/", 
            "text": "This training documentation is coded in this GitHub\n\nrepository\n\n\nWhy Running Galaxy as an administrator ?\n\n\nYou may be wondering: \"Why doing all this geeky IT stuff when I have access to Galaxy\nservers administrated by professional ?\"\n\n\nIt is true that there is a lot of powerful Galaxy instances, and at first, \nthe \nmain Galaxy instance\n. The expanding list of\npublic galaxy servers is available \nhere\n.\n\n\nHowever, a number of issues listed below (non-exhaustive list) can be successfully addressed\nif you are able to run and administrate your own Galaxy server:\n\n\n\n\n\n\nStorage/Disk Space.\n\n\nMost of Public Galaxy Servers provide their users with a quota that rarely exceed 200-300\nGiga-bytes. Although this may seem a lot, it is not unfrequent that analyses that deal with\nnumerous samples require 1 Tera-bytes or more.\n\n\nWhen you administrate your Galaxy server, you control your storage space. Of course,\nsince nothing in free in this world, keep in mind that you will have to support for the\ncost of this storage.\n\n\n\n\n\n\n\n\nIsolation.\n\n\nIf you control a Galaxy server for a given analysis project and only for this project,\nyou can argue that you benefit from an analysis environment that is isolated.\n\n\n\n\n\n\n\n\nAccessibility and Reproducibility\n\n\nWhenever you need to give access to collaborators or reviewers to your work, giving access\nto your Galaxy server is enough to provide high-quality transparency and reproducibility.\nThis is far better than just sharing public histories, since when you are not administrator,\nyou do not have access to all computational details that are logged for Galaxy admins.\nMoreover, if you deploy you Galaxy server in a virtual environment (VM or docker containers)\nyou can preserve the whole environment in an archive and redeploy this environment latter\non in another environment.\n\n\n\n\n\n\n\n\nComputational Resources.\n\n\nAlthough Galaxy public servers are generally hosted in high performance computing\ninfrastructures, they - by definition - share these resources between users. For instance,\nthe main Galaxy server is hosted by\n\na network of US supercomputers\n. Nevertheless, the\ncomputational walltime for a user to execute standards analyses (BWA, bowtie, Tophat,\nTrinity, etc.) may easily exceed 5 or 6 hours.\n\n\nLikewise, some metagenomic or \nde novo\n assembly approaches may require a substantial\namount of memory that is not necessarily provided by public Galaxy server.\n\n\n\n\n\n\n\n\nFull control on installed tools\n\n\nYou may need a particular combination of tools for your analysis, and this combination\nmay not be available in any public server. Although Galaxy admin are generally happy to\ninstall new tools for their users, other considerations that have to be taken into account\nin a public resource may limit installation of new tools: not considered as harmless for\nthe server, competing with the public resource, not in the policy of the thematic Galaxy\nserver, etc.\nWhen you administrate your Galaxy server, you can install the tool you need, exactly as\nyou wish them.\nYou can even modify tools, or code your own tools and test these tools in live in your\nGalaxy instance.\nLast, but not least, when you are administrator, you have access to information on tool\n\n workflow runs you cannot access to when you are regular users (some metadata, including\nrunning times, command lines, etc.)\n\n\n\n\n\n\n\n\nFull Control on computational workflows.\n\n\nGalaxy workflows can be exchanged between researchers and between Galaxy instances.\nHowever, to be effective, this interoperability requires that the tools called by an\nimported workflow are installed in the new Galaxy instance.\nYou can only do that if your are administrator of this Galaxy instance.\n\n\n\n\n\n\n\n\nHelp your community.\n\n\nGalaxy administration is a very useful expertise: you can greatly\nhelp your colleagues if you are able to run a Galaxy server for them !", 
            "title": "Introduction: Why Running Galaxy as an administrator?"
        }, 
        {
            "location": "/#why-running-galaxy-as-an-administrator", 
            "text": "You may be wondering: \"Why doing all this geeky IT stuff when I have access to Galaxy\nservers administrated by professional ?\"  It is true that there is a lot of powerful Galaxy instances, and at first, \nthe  main Galaxy instance . The expanding list of\npublic galaxy servers is available  here .  However, a number of issues listed below (non-exhaustive list) can be successfully addressed\nif you are able to run and administrate your own Galaxy server:    Storage/Disk Space.  Most of Public Galaxy Servers provide their users with a quota that rarely exceed 200-300\nGiga-bytes. Although this may seem a lot, it is not unfrequent that analyses that deal with\nnumerous samples require 1 Tera-bytes or more.  When you administrate your Galaxy server, you control your storage space. Of course,\nsince nothing in free in this world, keep in mind that you will have to support for the\ncost of this storage.     Isolation.  If you control a Galaxy server for a given analysis project and only for this project,\nyou can argue that you benefit from an analysis environment that is isolated.     Accessibility and Reproducibility  Whenever you need to give access to collaborators or reviewers to your work, giving access\nto your Galaxy server is enough to provide high-quality transparency and reproducibility.\nThis is far better than just sharing public histories, since when you are not administrator,\nyou do not have access to all computational details that are logged for Galaxy admins.\nMoreover, if you deploy you Galaxy server in a virtual environment (VM or docker containers)\nyou can preserve the whole environment in an archive and redeploy this environment latter\non in another environment.     Computational Resources.  Although Galaxy public servers are generally hosted in high performance computing\ninfrastructures, they - by definition - share these resources between users. For instance,\nthe main Galaxy server is hosted by a network of US supercomputers . Nevertheless, the\ncomputational walltime for a user to execute standards analyses (BWA, bowtie, Tophat,\nTrinity, etc.) may easily exceed 5 or 6 hours.  Likewise, some metagenomic or  de novo  assembly approaches may require a substantial\namount of memory that is not necessarily provided by public Galaxy server.     Full control on installed tools  You may need a particular combination of tools for your analysis, and this combination\nmay not be available in any public server. Although Galaxy admin are generally happy to\ninstall new tools for their users, other considerations that have to be taken into account\nin a public resource may limit installation of new tools: not considered as harmless for\nthe server, competing with the public resource, not in the policy of the thematic Galaxy\nserver, etc.\nWhen you administrate your Galaxy server, you can install the tool you need, exactly as\nyou wish them.\nYou can even modify tools, or code your own tools and test these tools in live in your\nGalaxy instance.\nLast, but not least, when you are administrator, you have access to information on tool  workflow runs you cannot access to when you are regular users (some metadata, including\nrunning times, command lines, etc.)     Full Control on computational workflows.  Galaxy workflows can be exchanged between researchers and between Galaxy instances.\nHowever, to be effective, this interoperability requires that the tools called by an\nimported workflow are installed in the new Galaxy instance.\nYou can only do that if your are administrator of this Galaxy instance.     Help your community.  Galaxy administration is a very useful expertise: you can greatly\nhelp your colleagues if you are able to run a Galaxy server for them !", 
            "title": "Why Running Galaxy as an administrator ?"
        }, 
        {
            "location": "/Training_menu/", 
            "text": "Training Menu\n\n\nThree methods of Galaxy server deployment will be explained in this tutorial, which can be\nused with personal computers, clusters of machines or virtual machines in cloud computing\nenvironment.\n\n\nAll you need is an ssh access and the control of tcp/ip ports of the target machine.\nThese two conditions are far more easily fulfilled with virtual machines in clouds. This is\nthe reason why we are going to use\n\nvirtual machines in the Google Cloud Engine\n. \n\n\nOutline of the training session\n\n\n\n\n1. Deployment of a Galaxy server in a VM using \ngit\n\n\n2. Deployment of a Galaxy server using \nAnsible\n\n\n3. Use case of Galaxy administration:\n\n\n\n\nInstall a computational workflow\n\n\nInstall tools for its proper execution\n\n\nRunning the workflow.\n\n\n\n\n4. Deployment of a Galaxy server using \nDocker\n\n\n5. Packaging and distribution of a virtual machine.", 
            "title": "Training Menu"
        }, 
        {
            "location": "/Training_menu/#training-menu", 
            "text": "Three methods of Galaxy server deployment will be explained in this tutorial, which can be\nused with personal computers, clusters of machines or virtual machines in cloud computing\nenvironment.  All you need is an ssh access and the control of tcp/ip ports of the target machine.\nThese two conditions are far more easily fulfilled with virtual machines in clouds. This is\nthe reason why we are going to use virtual machines in the Google Cloud Engine .", 
            "title": "Training Menu"
        }, 
        {
            "location": "/Training_menu/#outline-of-the-training-session", 
            "text": "", 
            "title": "Outline of the training session"
        }, 
        {
            "location": "/Training_menu/#1-deployment-of-a-galaxy-server-in-a-vm-using-git", 
            "text": "", 
            "title": "1. Deployment of a Galaxy server in a VM using git"
        }, 
        {
            "location": "/Training_menu/#2-deployment-of-a-galaxy-server-using-ansible", 
            "text": "", 
            "title": "2. Deployment of a Galaxy server using Ansible"
        }, 
        {
            "location": "/Training_menu/#3-use-case-of-galaxy-administration", 
            "text": "Install a computational workflow  Install tools for its proper execution  Running the workflow.", 
            "title": "3. Use case of Galaxy administration:"
        }, 
        {
            "location": "/Training_menu/#4-deployment-of-a-galaxy-server-using-docker", 
            "text": "", 
            "title": "4. Deployment of a Galaxy server using Docker"
        }, 
        {
            "location": "/Training_menu/#5-packaging-and-distribution-of-a-virtual-machine", 
            "text": "", 
            "title": "5. Packaging and distribution of a virtual machine."
        }, 
        {
            "location": "/bare-galaxy/", 
            "text": "Install a minimal galaxy server with git\n\n\nSpin off a virtual Machine \nbare-galaxy\n\n\nYou may have already done this in the \nprevious section\n. If not, refer to this section\nWe are going to use a GCE VM \n- under \nUbuntu 16.04 LTS\n\n- \n2\n processors\n- \n7.5\n Gb RAM\n- a \n50 Gb\n Volume (more than enough)\n\n\nConnect to the VM as explained in \nthis section\n using the ssh web console\n\n\nInstallation of dependencies\n\n\nTo install Galaxy, we only need a few dependencies (i.e. pre-installed programs which Galaxy needs) and a limited number of command line.\nWe are going to execute these instruction as the \nroot\n unix user. This is easier because installation\nof new programs as well as manipulations of network interfaces is generally permitted only\nto users with administration rights.\n\n\nSo let's do this step by step:\n\n\n1. \nsudo -i\n\n\nThis command open a new \"shell\" where you are root. You can check this by typing \npwd\n that\nshould return \n/root/\n, meaning that you are now working in the directory of the \nroot\n user.\n\n\n2. \napt update -y\n\n\nThis command will just trigger an update of the program database in the Ubuntu OS.\n\n\n3. \napt install -y python-dev python-pip nano git\n\n\nThis command install some python programs (python-dev python-pip) that are intensively used by Galaxy,\n\nnano\n, a simple text editor we need, and the \ngit\n program which is the software to fetch,\nand update Galaxy (i.e. a sort of \"installer\" program). The \n-y\n option specifies to the \napt-get\n\npackage installer that no confirmation is needed for this command.\n\n\n4. \ngit clone https://github.com/galaxyproject/galaxy.git -b release_18.09\n\n\nThis command says to use \ngit\n to \nclone\n the code repository located at \nhttps://github.com/galaxyproject/galaxy.git\n.\nIn addition the \n-b release_18.09\n option specifies that only the version \nrelease_18.09\n will be cloned locally in your virtual machine.\nYou may try to visualize the URL \nhttps://github.com/galaxyproject/galaxy.git\n\nin your web browser. You will literally see the code of Galaxy !\n\n\n5. \ncd galaxy\n\n\nThis command shift you in the \ngalaxy\n directory that was created by git\n\n\n6. \ncp config/galaxy.yml.sample config/galaxy.yml\n\n\nThis command makes a copie of the \ngalaxy.yml.sample\n file into \ngalaxy.yml\n - in the\ndirectory \nconfig\n that is in the \ngalaxy\n directory.\n\n\n7. \nnano config/galaxy.yml\n\n\nUsing this command, we are going to edit some important settings that are required to run our Galaxy fresh instance.\n\n\n\n\nFind the line \nhttp: 127.0.0.1:8080\n and edit it to \nhttp: 0.0.0.0:80\n\n\n\n\nBy doing this, we ensure that we will be able to reach the galaxy web server on our virtual machine using the usual web port \n80\n.\n\n\n\n\nFind the line \n#admin_users: ''\n, delete the \n#\n character and type your email address between the two single quotes.\n\n\n\n\nAny email address is ok (me@myname.fr is you want). It is just used here as an admin identifier.\n\n\n\n\nsave your edits by pressing the key combination \nCtrl\n+\no\n\n\nquit nano by pressing the key combination \nCtrl\n+\nx\n\n\n\n\n8. Ready for the Big Bang ?\n\n\nThen type \nsh run.sh\n and press the \nenter\n key !\n\n\nYou should see an abundant log scrolling down. Don't worry !\n- All Galaxy dependencies required for the Galaxy server instance are being downloaded and installed\n- The Galaxy computing environment is automatically set up\n- the Galaxy web server is installed\n- The Galaxy database is automatically upgraded to the latest structure\n- Various tools are upgraded.\n\n\nAfter 8 minute or so, you should see the log freezing with\n\n\nStarting server in PID 3813.\nserving on http://127.0.0.1:80\n\n\n\n\n8. Connect to your living Galaxy instance\n\n\nIf so, this is all good, and you can now access to you Galaxy instance in a you web browser window:\n\n\nGo back to your Google Cloud Engine control panel. Find the \nExternal IP address\n / \nAdresse IP externe\n\nin the 7th column of the Dashbord (to the left of the ssh menu that you used before. And just click on the hyperlink.\n\n\n9. Connect as an admin of your Galaxy server instance\n\n\n\n\nRegister to your instance using the email address you put in the galaxy.yml at step 7 (menu \"Authentification et enregistrement --\n Enregistrement)\n\n\nNow that you are registered, you can log in using the same login and password you have chosen.\n\n\nAfter login, you will see the admin tab in the top menu of the Galaxy interface.\n\n\n\n\nYou are connected to Galaxy as an admin !", 
            "title": "Install a minimal standalone galaxy server"
        }, 
        {
            "location": "/bare-galaxy/#install-a-minimal-galaxy-server-with-git", 
            "text": "", 
            "title": "Install a minimal galaxy server with git"
        }, 
        {
            "location": "/bare-galaxy/#spin-off-a-virtual-machine-bare-galaxy", 
            "text": "You may have already done this in the  previous section . If not, refer to this section\nWe are going to use a GCE VM \n- under  Ubuntu 16.04 LTS \n-  2  processors\n-  7.5  Gb RAM\n- a  50 Gb  Volume (more than enough)", 
            "title": "Spin off a virtual Machine bare-galaxy"
        }, 
        {
            "location": "/bare-galaxy/#connect-to-the-vm-as-explained-in-this-section-using-the-ssh-web-console", 
            "text": "", 
            "title": "Connect to the VM as explained in this section using the ssh web console"
        }, 
        {
            "location": "/bare-galaxy/#installation-of-dependencies", 
            "text": "To install Galaxy, we only need a few dependencies (i.e. pre-installed programs which Galaxy needs) and a limited number of command line.\nWe are going to execute these instruction as the  root  unix user. This is easier because installation\nof new programs as well as manipulations of network interfaces is generally permitted only\nto users with administration rights.  So let's do this step by step:", 
            "title": "Installation of dependencies"
        }, 
        {
            "location": "/bare-galaxy/#1-sudo-i", 
            "text": "This command open a new \"shell\" where you are root. You can check this by typing  pwd  that\nshould return  /root/ , meaning that you are now working in the directory of the  root  user.", 
            "title": "1. sudo -i"
        }, 
        {
            "location": "/bare-galaxy/#2-apt-update-y", 
            "text": "This command will just trigger an update of the program database in the Ubuntu OS.", 
            "title": "2. apt update -y"
        }, 
        {
            "location": "/bare-galaxy/#3-apt-install-y-python-dev-python-pip-nano-git", 
            "text": "This command install some python programs (python-dev python-pip) that are intensively used by Galaxy, nano , a simple text editor we need, and the  git  program which is the software to fetch,\nand update Galaxy (i.e. a sort of \"installer\" program). The  -y  option specifies to the  apt-get \npackage installer that no confirmation is needed for this command.", 
            "title": "3. apt install -y python-dev python-pip nano git"
        }, 
        {
            "location": "/bare-galaxy/#4-git-clone-httpsgithubcomgalaxyprojectgalaxygit-b-release_1809", 
            "text": "This command says to use  git  to  clone  the code repository located at  https://github.com/galaxyproject/galaxy.git .\nIn addition the  -b release_18.09  option specifies that only the version  release_18.09  will be cloned locally in your virtual machine.\nYou may try to visualize the URL  https://github.com/galaxyproject/galaxy.git \nin your web browser. You will literally see the code of Galaxy !", 
            "title": "4. git clone https://github.com/galaxyproject/galaxy.git -b release_18.09"
        }, 
        {
            "location": "/bare-galaxy/#5-cd-galaxy", 
            "text": "This command shift you in the  galaxy  directory that was created by git", 
            "title": "5. cd galaxy"
        }, 
        {
            "location": "/bare-galaxy/#6-cp-configgalaxyymlsample-configgalaxyyml", 
            "text": "This command makes a copie of the  galaxy.yml.sample  file into  galaxy.yml  - in the\ndirectory  config  that is in the  galaxy  directory.", 
            "title": "6. cp config/galaxy.yml.sample config/galaxy.yml"
        }, 
        {
            "location": "/bare-galaxy/#7-nano-configgalaxyyml", 
            "text": "Using this command, we are going to edit some important settings that are required to run our Galaxy fresh instance.   Find the line  http: 127.0.0.1:8080  and edit it to  http: 0.0.0.0:80   By doing this, we ensure that we will be able to reach the galaxy web server on our virtual machine using the usual web port  80 .   Find the line  #admin_users: '' , delete the  #  character and type your email address between the two single quotes.   Any email address is ok (me@myname.fr is you want). It is just used here as an admin identifier.   save your edits by pressing the key combination  Ctrl + o  quit nano by pressing the key combination  Ctrl + x", 
            "title": "7. nano config/galaxy.yml"
        }, 
        {
            "location": "/bare-galaxy/#8-ready-for-the-big-bang", 
            "text": "Then type  sh run.sh  and press the  enter  key !  You should see an abundant log scrolling down. Don't worry !\n- All Galaxy dependencies required for the Galaxy server instance are being downloaded and installed\n- The Galaxy computing environment is automatically set up\n- the Galaxy web server is installed\n- The Galaxy database is automatically upgraded to the latest structure\n- Various tools are upgraded.  After 8 minute or so, you should see the log freezing with  Starting server in PID 3813.\nserving on http://127.0.0.1:80", 
            "title": "8. Ready for the Big Bang ?"
        }, 
        {
            "location": "/bare-galaxy/#8-connect-to-your-living-galaxy-instance", 
            "text": "If so, this is all good, and you can now access to you Galaxy instance in a you web browser window:  Go back to your Google Cloud Engine control panel. Find the  External IP address  /  Adresse IP externe \nin the 7th column of the Dashbord (to the left of the ssh menu that you used before. And just click on the hyperlink.", 
            "title": "8. Connect to your living Galaxy instance"
        }, 
        {
            "location": "/bare-galaxy/#9-connect-as-an-admin-of-your-galaxy-server-instance", 
            "text": "Register to your instance using the email address you put in the galaxy.yml at step 7 (menu \"Authentification et enregistrement --  Enregistrement)  Now that you are registered, you can log in using the same login and password you have chosen.  After login, you will see the admin tab in the top menu of the Galaxy interface.", 
            "title": "9. Connect as an admin of your Galaxy server instance"
        }, 
        {
            "location": "/bare-galaxy/#you-are-connected-to-galaxy-as-an-admin", 
            "text": "", 
            "title": "You are connected to Galaxy as an admin !"
        }, 
        {
            "location": "/Run_workflow/", 
            "text": "Running a workflow in Galaxy\n\n\nIn this use case, we are going to\n\n\n\n\nUpload 2 workflow description files in the Galaxy server instance\n\n\nVisualise these workflows and see that tools to execute the workflows are missing\n\n\nsince you are administrating the instance\n, install the missing tools\n\n\nEventually run the workflows on input data obtained from a remote public repository.\n\n\n\n\nUpload workflow description file (.ga)\n\n\n\n\nEnsure you are connected to your Galaxy server as an admin (the email you have entered\nin the galaxy.yml configuration file and the password to entered for this login when you\nregistered for the first time)\n\n\nClick the workflow menu\n\n\nClick the \"Upload or import workflow\" button at the top right\n\n\nIn the \nGalaxy workflow URL:\n field, paste the url of the workflow file:\n\n\n\n\nhttps://raw.githubusercontent.com/ARTbio/Run-Galaxy/master/workflows/Galaxy-Workflow-canonical_transposons.gtf_from_transposon_sequence_set.txt.ga\n\n\nNote that this file is in the \nRun-Galaxy\n repository where all the material for this training\nis hosted\n\n\n\n\n\n\nrepeat the same operation with the other workflow \n\nhttps://raw.githubusercontent.com/ARTbio/Run-Galaxy/master/workflows/Galaxy-Workflow-Extract_canonical_transposons_fasta.ga\n\n\n\n\n\n\n(alternatively, you could upload the workflow files from you computer instead of uploading them by URL)\n\n\n\n\n\n\nClick on the \nImport\n button\n\n\n\n\n\n\nObserve the numerous warning returned by the galaxy server when it imported the workflow file.\nin a red scary window\n\n\n\n\n\n\n\n\nWhen you read the warnings, you will see that the workflow was indeed successfully imported.\nHowever, tools are missing, namely:\n\n\ntoolshed.g2.bx.psu.edu/repos/kellrott/regex_replace/regex_replace/1.0.0, version 1.0.0\ntoolshed.g2.bx.psu.edu/repos/blankenberg/column_regex_substitution/column_regex_substitution/0.1.0, version 0.1.0\ntoolshed.g2.bx.psu.edu/repos/jjohnson/regex_find_replace/regex_find_replace/0.1.0, version 0.1.0\n\n\n\n\nThe other lines are redundant, because the workflow is using the same tools at different steps.\n\n\n\n\n\n\nSo far, so good, the missing tools are reported in the \ntools.yml\n\nfile in the Run-Galaxy repository (or just above in a more complex format)\n\n\n\n\n\n\nNow, click on the workflow menu.\n\n\n\n\n\n\nYou should see the imported workflow in the list:\n\n\n\n\n\n\nClick the workflow and select the \nEdit\n option\n\n\nDismiss the warnings (You are already aware of it) by clicking the \nContinue\n button\n\n\nSee again in the editor window, all the missing steps in red. At this stage you can't\neven see anymore the paths between the various workflow steps !\n\n\nClick the upper \"wheel\" icon and select \nClose\n, we will come back to this when the missing tools are installed in the Server !\n\n\n\n\nInstalling missing tools\n\n\nSo, we have to install our first three tools in our Galaxy instance:\n\n\ntools:\n- name: regex_replace\n  owner: kellrott\n  revisions:\n  - 9a77d5fca67c\n  tool_panel_section_label: biologie des genomes\n  tool_shed_url: https://toolshed.g2.bx.psu.edu\n\n\n\n\nname: column_regex_substitution\n  owner: blankenberg\n  revisions:\n\n\n\n\n12b740c4cbc1\n  tool_panel_section_label: biologie des genomes\n  tool_shed_url: https://toolshed.g2.bx.psu.edu\n\n\n\n\n\n\nname: regex_find_replace\n  owner: jjohnson\n  revisions:\n\n\n\n\n\n\n9ea374bb0350\n  tool_panel_section_label: biologie des genomes\n  tool_shed_url: https://toolshed.g2.bx.psu.edu\n\n\n\n\n\n\nClick on the \nAdmin\n top menu\n\n\n\n\nOn the left bar click on \nManage installed tools\n\n\n\n\nYou'll see a single lonely tool \nyac_clipper\n, which you probably already used\nto remove adapter sequences for small-RNA-seq data.\n\n\n\n\nNow, click the \nSearch Tool Shed\n menu (again in the left bar)\n\n\nPress the \nGalaxy Main Tool Shed\n button\n\n\nIn the search field, copy and paste \nregex_replace\n, and press the \nenter\n key.\n\n\nOne tool will show up, owned by \nkellrott\n.\n    Click this tool, and select \npreview and install\n (No other solution anyway)\n\n\nClick the \nInstall to Galaxy\n button at the top of the screen\n\n\nIn the \nSelect existing tool panel section:\n menu, select \nText Manipulation\n.\nThus, the tools will appears in the section \nText Manipulation\n of the Galaxy tools.\n\n\nClick \nInstall\n\n\nYou are going to wait for ~20 sec or so, before seeing the \nMonitor installing tools...\n screen.\n\n\nRapidly enough, the Installation status should turn out green. Sometimes, things do not go well.\nIf the installation fails, just call the \nRepository Actions - repair repository\n menu\n(maybe a good idea to call me too...)\n\n\n\n\nClick again the \nManage tools\n menu in the left bar, and look at the newly\ninstalled tool \nregex_find_replace\n in the list.\n\n\n\n\n\n\nRepeat the same operations for the tool \nregex_find_replace\n owned by \njjohnson\n(version \n1.1.0\n)\n\n\n\n\n\n\nRepeat the same operations for the tool \ncolumn_regex_substitution\n owned by \nblankenberg\n (version \n0.0.1\n)\n\n\n\n\n\n\nFor this last installation, you will see a different panel after clicking \nInstall to Galaxy\n:\n   If you scroll down a little bit, you should see a list of uninstalled tool dependencies like this:\n   \n\n\nThese are software packages required to get the tool \ncolumn_regex_substitution\n working properly.\n   The required package (python 2.7) will be installed by the lately adopted package manager \nconda\n.\n   You can further check this by clicking the \nDisplay Details\n button bellow the Dependency list.\n\n\nAt this stage, avoid further distraction and do not forget to select tool panel section\n   \nText Manipulation\n, and finally click the \nInstall\n button.\n   This time, the \nMonitor installing tool shed repositories\n will display new steps (in yellow),\n   including the \nInstalling tool dependencies\n step. The whole process may take longer,\n   but not too long in this specific case.\n- Finally go back a last time to the \nManage installed tools\n panel:\n\n\n\n\nThere you see all three tools needed to properly run the imported workflow.\n\n\n\nCheck that the imported workflows now display correctly\n\n\nIf you click the \nworkflow\n top menu, you should now be able to edit the imported workflows,\nand see that everything is displaying correctly:\n\n\n\n\nWe can go through the various steps of the workflows and figure out what they are doing.\n\n\nThe first workflow  performs a suite of find-and-replace text manipulations, starting\nfrom input data that has been tagged \ntransposon_set_embl.txt\n and producing a new text\ndataset that is renamed \ncanonical_transposons.gtf\n.\n\n\nThe second workflow uses the same input data file \ntransposon_set_embl.txt\n to generate\na fasta file of canonical_transposon sequences\n\n\nWe will come back to all these steps after the workflows execution. However, we need to\nretrieve the input data set before running the workflow on these data.\n\n\nRetrieve the \ntransposon_set_embl.txt\n dataset\n\n\n\n\nCreate a new history and name it \ntransposon_set_embl.txt manipulation\n\n\nimport the dataset using the \nPaste/Fetch data\n mode of the upload manager (the small\nbottom-top arrow icone at the top left of the Galaxy interface). Copy the URL\n\nhttps://github.com/cbergman/transposons/raw/master/current/transposon_sequence_set.embl.txt\n\nin the open field and click the \nStart\n button.\n\n\nhave a close look at the file\n\n\n\n\nRun the workflow\n\n\n\n\nClick on the workflow menu\n\n\nClick on the workflow and select the Run option\n\n\nLeave the \nSend results to a new history\n menu to the \nNo\n option for the moment.\n\n\nJust Click the \nRun workflow\n button to run the workflow, and look at datasets in the\nhistory turning from grey to yellow to green. Note: often you don't see the dataset in the\n\"yellow\" state (running). You just need to refresh the history with the 2-curved-arrows\nicon of the local history menu.\n\n\n\n\nDiscussion on workflows", 
            "title": "After deployment use case"
        }, 
        {
            "location": "/Run_workflow/#running-a-workflow-in-galaxy", 
            "text": "", 
            "title": "Running a workflow in Galaxy"
        }, 
        {
            "location": "/Run_workflow/#in-this-use-case-we-are-going-to", 
            "text": "Upload 2 workflow description files in the Galaxy server instance  Visualise these workflows and see that tools to execute the workflows are missing  since you are administrating the instance , install the missing tools  Eventually run the workflows on input data obtained from a remote public repository.", 
            "title": "In this use case, we are going to"
        }, 
        {
            "location": "/Run_workflow/#upload-workflow-description-file-ga", 
            "text": "Ensure you are connected to your Galaxy server as an admin (the email you have entered\nin the galaxy.yml configuration file and the password to entered for this login when you\nregistered for the first time)  Click the workflow menu  Click the \"Upload or import workflow\" button at the top right  In the  Galaxy workflow URL:  field, paste the url of the workflow file:   https://raw.githubusercontent.com/ARTbio/Run-Galaxy/master/workflows/Galaxy-Workflow-canonical_transposons.gtf_from_transposon_sequence_set.txt.ga  Note that this file is in the  Run-Galaxy  repository where all the material for this training\nis hosted    repeat the same operation with the other workflow  https://raw.githubusercontent.com/ARTbio/Run-Galaxy/master/workflows/Galaxy-Workflow-Extract_canonical_transposons_fasta.ga    (alternatively, you could upload the workflow files from you computer instead of uploading them by URL)    Click on the  Import  button    Observe the numerous warning returned by the galaxy server when it imported the workflow file.\nin a red scary window     When you read the warnings, you will see that the workflow was indeed successfully imported.\nHowever, tools are missing, namely:  toolshed.g2.bx.psu.edu/repos/kellrott/regex_replace/regex_replace/1.0.0, version 1.0.0\ntoolshed.g2.bx.psu.edu/repos/blankenberg/column_regex_substitution/column_regex_substitution/0.1.0, version 0.1.0\ntoolshed.g2.bx.psu.edu/repos/jjohnson/regex_find_replace/regex_find_replace/0.1.0, version 0.1.0  The other lines are redundant, because the workflow is using the same tools at different steps.    So far, so good, the missing tools are reported in the  tools.yml \nfile in the Run-Galaxy repository (or just above in a more complex format)    Now, click on the workflow menu.    You should see the imported workflow in the list:    Click the workflow and select the  Edit  option  Dismiss the warnings (You are already aware of it) by clicking the  Continue  button  See again in the editor window, all the missing steps in red. At this stage you can't\neven see anymore the paths between the various workflow steps !  Click the upper \"wheel\" icon and select  Close , we will come back to this when the missing tools are installed in the Server !", 
            "title": "Upload workflow description file (.ga)"
        }, 
        {
            "location": "/Run_workflow/#installing-missing-tools", 
            "text": "So, we have to install our first three tools in our Galaxy instance:  tools:\n- name: regex_replace\n  owner: kellrott\n  revisions:\n  - 9a77d5fca67c\n  tool_panel_section_label: biologie des genomes\n  tool_shed_url: https://toolshed.g2.bx.psu.edu   name: column_regex_substitution\n  owner: blankenberg\n  revisions:   12b740c4cbc1\n  tool_panel_section_label: biologie des genomes\n  tool_shed_url: https://toolshed.g2.bx.psu.edu    name: regex_find_replace\n  owner: jjohnson\n  revisions:    9ea374bb0350\n  tool_panel_section_label: biologie des genomes\n  tool_shed_url: https://toolshed.g2.bx.psu.edu    Click on the  Admin  top menu   On the left bar click on  Manage installed tools   You'll see a single lonely tool  yac_clipper , which you probably already used\nto remove adapter sequences for small-RNA-seq data.   Now, click the  Search Tool Shed  menu (again in the left bar)  Press the  Galaxy Main Tool Shed  button  In the search field, copy and paste  regex_replace , and press the  enter  key.  One tool will show up, owned by  kellrott .\n    Click this tool, and select  preview and install  (No other solution anyway)  Click the  Install to Galaxy  button at the top of the screen  In the  Select existing tool panel section:  menu, select  Text Manipulation .\nThus, the tools will appears in the section  Text Manipulation  of the Galaxy tools.  Click  Install  You are going to wait for ~20 sec or so, before seeing the  Monitor installing tools...  screen.  Rapidly enough, the Installation status should turn out green. Sometimes, things do not go well.\nIf the installation fails, just call the  Repository Actions - repair repository  menu\n(maybe a good idea to call me too...)   Click again the  Manage tools  menu in the left bar, and look at the newly\ninstalled tool  regex_find_replace  in the list.    Repeat the same operations for the tool  regex_find_replace  owned by  jjohnson (version  1.1.0 )    Repeat the same operations for the tool  column_regex_substitution  owned by  blankenberg  (version  0.0.1 )    For this last installation, you will see a different panel after clicking  Install to Galaxy :\n   If you scroll down a little bit, you should see a list of uninstalled tool dependencies like this:\n     These are software packages required to get the tool  column_regex_substitution  working properly.\n   The required package (python 2.7) will be installed by the lately adopted package manager  conda .\n   You can further check this by clicking the  Display Details  button bellow the Dependency list.  At this stage, avoid further distraction and do not forget to select tool panel section\n    Text Manipulation , and finally click the  Install  button.\n   This time, the  Monitor installing tool shed repositories  will display new steps (in yellow),\n   including the  Installing tool dependencies  step. The whole process may take longer,\n   but not too long in this specific case.\n- Finally go back a last time to the  Manage installed tools  panel:   There you see all three tools needed to properly run the imported workflow.", 
            "title": "Installing missing tools"
        }, 
        {
            "location": "/Run_workflow/#check-that-the-imported-workflows-now-display-correctly", 
            "text": "If you click the  workflow  top menu, you should now be able to edit the imported workflows,\nand see that everything is displaying correctly:   We can go through the various steps of the workflows and figure out what they are doing.  The first workflow  performs a suite of find-and-replace text manipulations, starting\nfrom input data that has been tagged  transposon_set_embl.txt  and producing a new text\ndataset that is renamed  canonical_transposons.gtf .  The second workflow uses the same input data file  transposon_set_embl.txt  to generate\na fasta file of canonical_transposon sequences  We will come back to all these steps after the workflows execution. However, we need to\nretrieve the input data set before running the workflow on these data.", 
            "title": "Check that the imported workflows now display correctly"
        }, 
        {
            "location": "/Run_workflow/#retrieve-the-transposon_set_embltxt-dataset", 
            "text": "Create a new history and name it  transposon_set_embl.txt manipulation  import the dataset using the  Paste/Fetch data  mode of the upload manager (the small\nbottom-top arrow icone at the top left of the Galaxy interface). Copy the URL https://github.com/cbergman/transposons/raw/master/current/transposon_sequence_set.embl.txt \nin the open field and click the  Start  button.  have a close look at the file", 
            "title": "Retrieve the transposon_set_embl.txt dataset"
        }, 
        {
            "location": "/Run_workflow/#run-the-workflow", 
            "text": "Click on the workflow menu  Click on the workflow and select the Run option  Leave the  Send results to a new history  menu to the  No  option for the moment.  Just Click the  Run workflow  button to run the workflow, and look at datasets in the\nhistory turning from grey to yellow to green. Note: often you don't see the dataset in the\n\"yellow\" state (running). You just need to refresh the history with the 2-curved-arrows\nicon of the local history menu.", 
            "title": "Run the workflow"
        }, 
        {
            "location": "/Run_workflow/#discussion-on-workflows", 
            "text": "", 
            "title": "Discussion on workflows"
        }, 
        {
            "location": "/GalaxyKickStart/", 
            "text": "Installation of a Galaxy server with Ansible and the GalaxyKickStart playbook\n\n\nWhat is Ansible ?\n\n\n\n\nAnsible is an automation engine that automates configuration management and application\ndeployment.\n\n\nAnsible reads instructions (Tasks) from a playbook and performs the indicated tasks on\ntarget machines (Hosts), through an ssh connection.\n\n\nThere is no magics: everything an \"administrator\" can do using command lines of a linux OS,\ncan be automated with ansible that \"wraps\" these command lines.\nThe power of Ansible (and similar orchestration software, ie Puppet, Chief, etc.) comes\nfrom the abstraction of complex suite of commands in the Ansible syntax.\nMoreover, automation allows to reproduce exactly the desired configuration.\nFinally, Ansible is \nidempotent\n: whatever the initial configuration, it brings the target\nto the exact same final state. This is useful to repair a broken configuration.\n\n\nAnsible playbook - GalaxyKickStart\n\n\nThe Ansible \"language\" (Striclty speaking, Ansible language is \nnot\n a programming language)\nis structured. Thus a playbook is not necessarily a single flat file. Multiple tasks can be gathered in a file, a \"role\" is the execution of a set of tasks, and a playbook can execute multiple roles.\n\n\nGalaxyKickStart is an Ansible playbook that will\n\n\n\n\ninstall basic dependencies needed for Galaxy\n\n\nCreate and manage all the linux users involved in the deployment of Galaxy\n\n\nInstall and configure the services required for Galaxy:\n\n\npostgresql (database engine)\n\n\nnginx (web server)\n\n\ndocker (containers)\n\n\nproftpd (ftp server)\n\n\nslurm (job manager)\n\n\nsupervisor (service manager)\n\n\nConfigure Galaxy for using these services\n\n\nInstall tools and workflows using the bioblend API.\n\n\n\n\nThe code of the GalaxyKickStart playbook is freely available at the ARTbio GitHub\nRepository \nhttps://github.com/ARTbio/GalaxyKickStart\n.\n\n\nDeployment\n\n\n\n\nstart a GCE VM \n2 procs, 7.5Gb RAM, Ubuntu 16.04, 50 Go disk, http enabled\n\n\nconnect to you VM using the Google ssh console\n\n\nstart an interactive session as root using the command \nsudo -i\n\n\ndownload the script \nrun_galaxykickstart.sh\n using the command \nwget https://raw.githubusercontent.com/ARTbio/Run-Galaxy/master/deployment_scripts/run_galaxykickstart.sh\n\n\nrun the script using the command \nsh run_galaxykickstart.sh\n\n\n\n\nConnect to your ansible-deployed \"GalaxyKickStart\" instance:\n\n\nJust click on the url displayed in your Google Cloud Engine Console.\n\n\n\n\n\n\nConnect to your server as an admin:\n\n\nThis time, ansible and the GalaxyKickStart playbook already programmatically registered\nan admin user. Just use the \nadmin@galaxy.org:admin\n as credentials (user:password)\n\n\n\n\n\n\nthe run_galaxykickstart.sh script explained\n\n\nNB: in the following code, numbers in line heads should be removed to run the script.\n\n\nset -e\napt update -y\napt install -y python-pip python-dev python-setuptools git htop\necho \nUpgrading pip\n\npip install -U pip\npip --version\n/usr/local/bin/pip install ansible==2.4\nansible --version\ngit clone https://github.com/ARTbio/GalaxyKickStart.git -b biologie_genome_2018\ncd GalaxyKickStart/\nansible-galaxy install -r requirements_roles.yml -p roles/ -f\nansible-playbook -i inventory_files/galaxy-kickstart galaxy.yml\necho \nSleeping 15 sec before restarting Galaxy server\n\necho \nzzzz zzzz...\n\nsleep 15\nsupervisorctl restart galaxy:\n\n\n\n\n\n\nThe shebang line (\n#!\n) says that it is a script code that has to be executed\n\n\nupdate apt package database\nby the shell bash which can be found in the /usr/bin/env environment\n\n\nset -e says to the bash interpreter to exit the run at first error (to avoid catastrophes)\n\n\ninstall \npython-pip\n, \npython-dev\n, \npython-setuptools\n (these 3 packages are required to\ninstall pip), \ngit\n (to clone and manage GitHub repositories) and \nhtop\n (a monitoring tool)\nusing the package installer \napt-get\n\n\nIs just a command to inform the user about run state. This will prompt\n\"Upgrading pip version\" in the console\n\n\ndoes what is stated before ! : this is the command to upgrade the pip program that was\ninstalled with installation of \npython-pip\n, \npython-dev\n and \npython-setuptools\n.\n\npip\n is a recursive acronym that can stand for either \"Pip Installs Packages\" or\n\"Pip Installs Python\".\n\n\nwill prompt the version of pip in the console\n\n\ninstall \nansible\n, version 2.4, using \npip\n !\n\n\nwill prompt the version of ansible in the console\n\n\nclone the GalaxyKickStart Repository available at https://github.com/ARTbio/GalaxyKickStart.git,\nbranch \nbiogen2018\n, creating locally the \nGalaxyKickStart\n folder.\n\n\nChange directory, ie goes to /root/GalaxyKickStart\n\n\nsays to ansible to install additional roles (collection of files to control ansible)\nwhich are not the the GalaxyKickStart repository but whose address is stated in the file\n\nrequirements_roles.yml\n. These roles will be installed in the subdirectory\n\n/root/GalaxyKickStart/roles/\n. NB: \nansible-galaxy\n has \nnothing\n to do with Galaxy,\nthe name of this ansible command is serendipitous.\n\n\nwarns about the next command\n\n\ntriggers the play of the playbook \ngalaxy.yml\n by ansible. The target host of the playbook\nis defined in the file \ninventory_files/galaxy-kickstart\n, as well as how ansible will interact with the target.\nHere, we play the playbook on the same computer (localhost).\n\n\nPrompt the effect of the command 17.\n\n\nPrompt the effect of the command 17.\n\n\nsleep for 15 seconds. This is to let the Galaxy server starting quietly.\n\n\nuse supervisor to restart the galaxy server: this is to load the more recent configuration\nfiles that may have been modified by the playbook \nafter\n the Galaxy server started.", 
            "title": "Install a Galaxy server with Ansible and GalaxyKickStart"
        }, 
        {
            "location": "/GalaxyKickStart/#installation-of-a-galaxy-server-with-ansible-and-the-galaxykickstart-playbook", 
            "text": "", 
            "title": "Installation of a Galaxy server with Ansible and the GalaxyKickStart playbook"
        }, 
        {
            "location": "/GalaxyKickStart/#what-is-ansible", 
            "text": "Ansible is an automation engine that automates configuration management and application\ndeployment.  Ansible reads instructions (Tasks) from a playbook and performs the indicated tasks on\ntarget machines (Hosts), through an ssh connection.  There is no magics: everything an \"administrator\" can do using command lines of a linux OS,\ncan be automated with ansible that \"wraps\" these command lines.\nThe power of Ansible (and similar orchestration software, ie Puppet, Chief, etc.) comes\nfrom the abstraction of complex suite of commands in the Ansible syntax.\nMoreover, automation allows to reproduce exactly the desired configuration.\nFinally, Ansible is  idempotent : whatever the initial configuration, it brings the target\nto the exact same final state. This is useful to repair a broken configuration.", 
            "title": "What is Ansible ?"
        }, 
        {
            "location": "/GalaxyKickStart/#ansible-playbook-galaxykickstart", 
            "text": "The Ansible \"language\" (Striclty speaking, Ansible language is  not  a programming language)\nis structured. Thus a playbook is not necessarily a single flat file. Multiple tasks can be gathered in a file, a \"role\" is the execution of a set of tasks, and a playbook can execute multiple roles.  GalaxyKickStart is an Ansible playbook that will   install basic dependencies needed for Galaxy  Create and manage all the linux users involved in the deployment of Galaxy  Install and configure the services required for Galaxy:  postgresql (database engine)  nginx (web server)  docker (containers)  proftpd (ftp server)  slurm (job manager)  supervisor (service manager)  Configure Galaxy for using these services  Install tools and workflows using the bioblend API.   The code of the GalaxyKickStart playbook is freely available at the ARTbio GitHub\nRepository  https://github.com/ARTbio/GalaxyKickStart .", 
            "title": "Ansible playbook - GalaxyKickStart"
        }, 
        {
            "location": "/GalaxyKickStart/#deployment", 
            "text": "start a GCE VM  2 procs, 7.5Gb RAM, Ubuntu 16.04, 50 Go disk, http enabled  connect to you VM using the Google ssh console  start an interactive session as root using the command  sudo -i  download the script  run_galaxykickstart.sh  using the command  wget https://raw.githubusercontent.com/ARTbio/Run-Galaxy/master/deployment_scripts/run_galaxykickstart.sh  run the script using the command  sh run_galaxykickstart.sh   Connect to your ansible-deployed \"GalaxyKickStart\" instance:  Just click on the url displayed in your Google Cloud Engine Console.    Connect to your server as an admin:  This time, ansible and the GalaxyKickStart playbook already programmatically registered\nan admin user. Just use the  admin@galaxy.org:admin  as credentials (user:password)", 
            "title": "Deployment"
        }, 
        {
            "location": "/GalaxyKickStart/#the-run_galaxykickstartsh-script-explained", 
            "text": "NB: in the following code, numbers in line heads should be removed to run the script.  set -e\napt update -y\napt install -y python-pip python-dev python-setuptools git htop\necho  Upgrading pip \npip install -U pip\npip --version\n/usr/local/bin/pip install ansible==2.4\nansible --version\ngit clone https://github.com/ARTbio/GalaxyKickStart.git -b biologie_genome_2018\ncd GalaxyKickStart/\nansible-galaxy install -r requirements_roles.yml -p roles/ -f\nansible-playbook -i inventory_files/galaxy-kickstart galaxy.yml\necho  Sleeping 15 sec before restarting Galaxy server \necho  zzzz zzzz... \nsleep 15\nsupervisorctl restart galaxy:   The shebang line ( #! ) says that it is a script code that has to be executed  update apt package database\nby the shell bash which can be found in the /usr/bin/env environment  set -e says to the bash interpreter to exit the run at first error (to avoid catastrophes)  install  python-pip ,  python-dev ,  python-setuptools  (these 3 packages are required to\ninstall pip),  git  (to clone and manage GitHub repositories) and  htop  (a monitoring tool)\nusing the package installer  apt-get  Is just a command to inform the user about run state. This will prompt\n\"Upgrading pip version\" in the console  does what is stated before ! : this is the command to upgrade the pip program that was\ninstalled with installation of  python-pip ,  python-dev  and  python-setuptools . pip  is a recursive acronym that can stand for either \"Pip Installs Packages\" or\n\"Pip Installs Python\".  will prompt the version of pip in the console  install  ansible , version 2.4, using  pip  !  will prompt the version of ansible in the console  clone the GalaxyKickStart Repository available at https://github.com/ARTbio/GalaxyKickStart.git,\nbranch  biogen2018 , creating locally the  GalaxyKickStart  folder.  Change directory, ie goes to /root/GalaxyKickStart  says to ansible to install additional roles (collection of files to control ansible)\nwhich are not the the GalaxyKickStart repository but whose address is stated in the file requirements_roles.yml . These roles will be installed in the subdirectory /root/GalaxyKickStart/roles/ . NB:  ansible-galaxy  has  nothing  to do with Galaxy,\nthe name of this ansible command is serendipitous.  warns about the next command  triggers the play of the playbook  galaxy.yml  by ansible. The target host of the playbook\nis defined in the file  inventory_files/galaxy-kickstart , as well as how ansible will interact with the target.\nHere, we play the playbook on the same computer (localhost).  Prompt the effect of the command 17.  Prompt the effect of the command 17.  sleep for 15 seconds. This is to let the Galaxy server starting quietly.  use supervisor to restart the galaxy server: this is to load the more recent configuration\nfiles that may have been modified by the playbook  after  the Galaxy server started.", 
            "title": "the run_galaxykickstart.sh script explained"
        }, 
        {
            "location": "/Docker_GalaxyKickStart/", 
            "text": "Installation of a Galaxy server with Docker\n\n\nWhat is Docker ?\n\n\n\n\nVirtual machines\n\n\nVirtual machines (VMs) are an abstraction of physical hardware turning one server into\nmany servers. The hypervisor allows multiple VMs to run on a single machine.\nEach VM includes a full copy of an operating system, one or more apps, necessary binaries\nand libraries - taking up tens of GBs. VMs can also be slow to boot.\n\n\nContainers\n\n\nContainers are an abstraction at the app layer that packages code and dependencies\ntogether. Multiple containers can run on the same machine and share the OS kernel with\nother containers, each running as isolated processes in user space. Containers take up\nless space than VMs (container images are typically tens of MBs in size), and start\nalmost instantly.\n\n\nGalaxyKickStart Docker \nContainer\n\n\nInstead of using the GalaxyKickStart playbook in a VM, the playbook can be used to build\na Docker container image that will be an almost exact mirror of the GalaxyKickStart VM\nyou have just built.\n\n\nYou are not going to do that today (although you should be able to do it by reading the instructions).\n\n\nInstead, you are going to\n\n\n\n\nInstall the \ndocker\n system\n\n\npull the GalaxyKickStart docker container that is deposited in the \nDocker Hub\n\n\nrun this docker container and connect to the deployed GalaxyKickStart server instance\n\n\n\n\nDeployment\n\n\n\n\nstart a GCE VM \n2 procs, 7.5Gb RAM, Ubuntu 14.04, 100 Go disk, http enabled\n\n\nconnect to you VM using the Google ssh console\n\n\nstart an interactive session as root using the command \nsudo -i\n\n\ndownload the script \ninstall_docker.sh\n using the command \nwget https://raw.githubusercontent.com/ARTbio/Run-Galaxy/master/deployment_scripts/install_docker.sh\n\n\nrun the script using the command \nsh install_docker.sh\n\n\n\n\nConnect to your ansible-deployed \"GalaxyKickStart\" instance:\n\n\nJust click on the url displayed in your Google Cloud Engine Console.\n\n\n\n\n\n\nThe install_docker.sh script explained\n\n\nNB: in the following code, numbers in line heads should be removed to run the script.\n\n\n1  #!/usr/bin/env bash\n2  set -e\n3  apt-key adv --recv-keys --keyserver hkp://p80.pool.sks-keyservers.net:80 58118E89F3A912897C070ADBF76221572C52609D\n4  add-apt-repository \ndeb https://apt.dockerproject.org/repo ubuntu-trusty main\n\n5  apt-get update -y\n6  apt-get -y install docker-engine\n7  echo \nDocker system is installed\\n\n\n8  echo \nNow pulling the galaxykickstart docker image from DockerHub\\n\n\n9  docker pull artbio/galaxykickstart\n10 echo \nRunning galaxykickstart docker container\\n\n\n11 export DOCKER_INSTANCE=`docker run -d -p 80:80 -p 21:21 -p 8800:8800 \\\n12           --privileged=true \\\n13           -e GALAXY_CONFIG_ALLOW_USER_DATASET_PURGE=True \\\n14           -e GALAXY_CONFIG_ALLOW_LIBRARY_PATH_PASTE=True \\\n15           -e GALAXY_CONFIG_ENABLE_USER_DELETION=True \\\n16           -e GALAXY_CONFIG_ENABLE_BETA_WORKFLOW_MODULES=True \\\n17           -v /tmp/:/tmp/ \\\n18           -v /export/:/export \\\n19           artbio/galaxykickstart`\n20 echo \nThe galaxykickstart docker container is up and running\\n\n\n21 echo \nPlease wait for a few secondes and interrupt logging when all services are launched\\n\n\n22 echo \nCtrl-C to stop logging\\n\\n\n\n23 docker logs -f $DOCKER_INSTANCE\n\n\n\n\n\n\nThe shebang line. Says that it is a script code and that the interpreter to execute the\ncode is bash and can be found in the /usr/bin/env environment\n\n\nset -e says to the bash interpreter to exit the run at first error (to avoid catastrophes)\n\n\ninstalls an authentication key to interact with the repository \napt.dockerproject.org\n that\nwill be declared in the next code line\n\n\nAdds the repository \nhttps://apt.dockerproject.org/repo\n to the system settings\n\n\nUpdates the system settings so that the added repo is registered for the apt-get program\n\n\nInstalls the Docker system as depicted in the figure above !\n\n\nreports to the terminal user\n\n\nreports to the terminal user\n\n\nPulls (Downloads) the Docker Image \nartbio/galaxykickstart\n from\nthe \nDockerHub repository\n\n\nreports to the terminal user\n\n\n\n\nLines 11 to 19 are actually a single command to run an instance of the galaxykickstart\ndocker image. Note the \n\\\n at ends of lines 11 to 18: this character \n\\\n specify that the\ncode line is continued without line break for the bash interpreter.\n\n\nThe line 11 starts with an \nexport DOCKER_INSTANCE=\n instruction. This means that the result\nof the command between ` after the sign \n=\n will be put in the environmental variable\n\nDOCKER_INSTANCE\n, available system-wide.\n\n\nNow, the docker command (between `) itself:\n\n\nStill in line 11, we have \ndocker run -d -p 80:80 -p 21:21 -p 8800:8800\n.\n\n\nThis means that a container will be run as a deamon (\n-d\n option) and that the internal\nTCP/IP ports 80 (web interface) and 21 (ftp interface) of the docker instance will be mapped\nto the ports 80 and 21 of your machin (The VM in this case). Note that in the syntax \n-p 80:80\n,\nthe host port is specified to the left of the \n:\n and the docker port is specified to the right\nof the \n:\n.\n\n\n\n\n\n\ndocker command continued: here we specify that the docker container acquires the root privileges\n\n\n\n\n\n\ndocker command continued: \n-e GALAXY_CONFIG_ALLOW_USER_DATASET_PURGE=True\n.\n\n\nThe -e option specifies an environmental variable \nGALAXY_CONFIG_ALLOW_USER_DATASET_PURGE\n\npassed (\ne\nxported) to the docker container with the value \nTrue\n\n\ngalaxy_manage_trackster: true\n with the string \ngalaxy_manage_trackster: false\n\nin the ansible configuration file \ngroups/all\n.\n\n\n\n\n\n\nThe environmental variable \nGALAXY_CONFIG_ALLOW_LIBRARY_PATH_PASTE\n is exported to\nthe docker container with the value \nTrue\n\n\n\n\nThe environmental variable \nGALAXY_CONFIG_ENABLE_USER_DELETION\n is exported to\nthe docker container with the value \nTrue\n\n\n\n\nThe environmental variable \nGALAXY_CONFIG_ENABLE_BETA_WORKFLOW_MODULES\n is exported to\nthe docker container with the value \nTrue\n\n\nNote that all these exports in the docker command correspond to advanced boiling/tuning of the docker container.\nYou are not obliged to understand the details to get the container properly running.\n17. Now the -v is important, better to understand it !\n\n\n-v stands for \"volume\". the \n-v\n option says to export the /tmp directory of the docker container\nto the /tmp directory of the host.\n18. we also export the /export directory of the container (any docker container has or\nshould have by default an /export directory) to an /export directory of the host (your VM here).\n\n\nNote that if the /export directory does not exists at docker run runtime, it will be created.\n\n\nSo it is important to understand the -v magics: every directory specified by the -v option will be shared\nbetween the docker container filesystem and the host filesystem. It is a mapping operation, so that\nthe same directory is accessible either from inside the docker container or from inside the host.\n\n\nNow, if you stop and remove the docker container, all exported directory will persist in the host.\nIf you don't do that, all operations performed with a container are lost when you stop this container !\n\n\n\n\n\n\nThis is the end of the docker run command. The docker image to be instantiated is specified.\n\n\n\n\nreports to the terminal user\n\n\nreports to the terminal user\n\n\nreports to the terminal user\n\n\nNow that the docker container is launched, you can access its logs with the command\n\ndocker logs -f\n (-f means continuous logging until keyboard interruption) followed by the\nidentification number of the docker container. We have put this ID in the variable \nDOCKER_INSTANCE\n\nand we access to the content of this variable by prefixing the variable with a \n$\n:\n\ndocker logs -f $DOCKER_INSTANCE", 
            "title": "Install a Galaxy server with Docker"
        }, 
        {
            "location": "/Docker_GalaxyKickStart/#installation-of-a-galaxy-server-with-docker", 
            "text": "", 
            "title": "Installation of a Galaxy server with Docker"
        }, 
        {
            "location": "/Docker_GalaxyKickStart/#what-is-docker", 
            "text": "", 
            "title": "What is Docker ?"
        }, 
        {
            "location": "/Docker_GalaxyKickStart/#virtual-machines", 
            "text": "Virtual machines (VMs) are an abstraction of physical hardware turning one server into\nmany servers. The hypervisor allows multiple VMs to run on a single machine.\nEach VM includes a full copy of an operating system, one or more apps, necessary binaries\nand libraries - taking up tens of GBs. VMs can also be slow to boot.", 
            "title": "Virtual machines"
        }, 
        {
            "location": "/Docker_GalaxyKickStart/#containers", 
            "text": "Containers are an abstraction at the app layer that packages code and dependencies\ntogether. Multiple containers can run on the same machine and share the OS kernel with\nother containers, each running as isolated processes in user space. Containers take up\nless space than VMs (container images are typically tens of MBs in size), and start\nalmost instantly.", 
            "title": "Containers"
        }, 
        {
            "location": "/Docker_GalaxyKickStart/#galaxykickstart-docker-container", 
            "text": "Instead of using the GalaxyKickStart playbook in a VM, the playbook can be used to build\na Docker container image that will be an almost exact mirror of the GalaxyKickStart VM\nyou have just built.  You are not going to do that today (although you should be able to do it by reading the instructions).  Instead, you are going to   Install the  docker  system  pull the GalaxyKickStart docker container that is deposited in the  Docker Hub  run this docker container and connect to the deployed GalaxyKickStart server instance", 
            "title": "GalaxyKickStart Docker Container"
        }, 
        {
            "location": "/Docker_GalaxyKickStart/#deployment", 
            "text": "start a GCE VM  2 procs, 7.5Gb RAM, Ubuntu 14.04, 100 Go disk, http enabled  connect to you VM using the Google ssh console  start an interactive session as root using the command  sudo -i  download the script  install_docker.sh  using the command  wget https://raw.githubusercontent.com/ARTbio/Run-Galaxy/master/deployment_scripts/install_docker.sh  run the script using the command  sh install_docker.sh   Connect to your ansible-deployed \"GalaxyKickStart\" instance:  Just click on the url displayed in your Google Cloud Engine Console.", 
            "title": "Deployment"
        }, 
        {
            "location": "/Docker_GalaxyKickStart/#the-install_dockersh-script-explained", 
            "text": "NB: in the following code, numbers in line heads should be removed to run the script.  1  #!/usr/bin/env bash\n2  set -e\n3  apt-key adv --recv-keys --keyserver hkp://p80.pool.sks-keyservers.net:80 58118E89F3A912897C070ADBF76221572C52609D\n4  add-apt-repository  deb https://apt.dockerproject.org/repo ubuntu-trusty main \n5  apt-get update -y\n6  apt-get -y install docker-engine\n7  echo  Docker system is installed\\n \n8  echo  Now pulling the galaxykickstart docker image from DockerHub\\n \n9  docker pull artbio/galaxykickstart\n10 echo  Running galaxykickstart docker container\\n \n11 export DOCKER_INSTANCE=`docker run -d -p 80:80 -p 21:21 -p 8800:8800 \\\n12           --privileged=true \\\n13           -e GALAXY_CONFIG_ALLOW_USER_DATASET_PURGE=True \\\n14           -e GALAXY_CONFIG_ALLOW_LIBRARY_PATH_PASTE=True \\\n15           -e GALAXY_CONFIG_ENABLE_USER_DELETION=True \\\n16           -e GALAXY_CONFIG_ENABLE_BETA_WORKFLOW_MODULES=True \\\n17           -v /tmp/:/tmp/ \\\n18           -v /export/:/export \\\n19           artbio/galaxykickstart`\n20 echo  The galaxykickstart docker container is up and running\\n \n21 echo  Please wait for a few secondes and interrupt logging when all services are launched\\n \n22 echo  Ctrl-C to stop logging\\n\\n \n23 docker logs -f $DOCKER_INSTANCE   The shebang line. Says that it is a script code and that the interpreter to execute the\ncode is bash and can be found in the /usr/bin/env environment  set -e says to the bash interpreter to exit the run at first error (to avoid catastrophes)  installs an authentication key to interact with the repository  apt.dockerproject.org  that\nwill be declared in the next code line  Adds the repository  https://apt.dockerproject.org/repo  to the system settings  Updates the system settings so that the added repo is registered for the apt-get program  Installs the Docker system as depicted in the figure above !  reports to the terminal user  reports to the terminal user  Pulls (Downloads) the Docker Image  artbio/galaxykickstart  from\nthe  DockerHub repository  reports to the terminal user   Lines 11 to 19 are actually a single command to run an instance of the galaxykickstart\ndocker image. Note the  \\  at ends of lines 11 to 18: this character  \\  specify that the\ncode line is continued without line break for the bash interpreter.  The line 11 starts with an  export DOCKER_INSTANCE=  instruction. This means that the result\nof the command between ` after the sign  =  will be put in the environmental variable DOCKER_INSTANCE , available system-wide.  Now, the docker command (between `) itself:  Still in line 11, we have  docker run -d -p 80:80 -p 21:21 -p 8800:8800 .  This means that a container will be run as a deamon ( -d  option) and that the internal\nTCP/IP ports 80 (web interface) and 21 (ftp interface) of the docker instance will be mapped\nto the ports 80 and 21 of your machin (The VM in this case). Note that in the syntax  -p 80:80 ,\nthe host port is specified to the left of the  :  and the docker port is specified to the right\nof the  : .    docker command continued: here we specify that the docker container acquires the root privileges    docker command continued:  -e GALAXY_CONFIG_ALLOW_USER_DATASET_PURGE=True .  The -e option specifies an environmental variable  GALAXY_CONFIG_ALLOW_USER_DATASET_PURGE \npassed ( e xported) to the docker container with the value  True  galaxy_manage_trackster: true  with the string  galaxy_manage_trackster: false \nin the ansible configuration file  groups/all .    The environmental variable  GALAXY_CONFIG_ALLOW_LIBRARY_PATH_PASTE  is exported to\nthe docker container with the value  True   The environmental variable  GALAXY_CONFIG_ENABLE_USER_DELETION  is exported to\nthe docker container with the value  True   The environmental variable  GALAXY_CONFIG_ENABLE_BETA_WORKFLOW_MODULES  is exported to\nthe docker container with the value  True  Note that all these exports in the docker command correspond to advanced boiling/tuning of the docker container.\nYou are not obliged to understand the details to get the container properly running.\n17. Now the -v is important, better to understand it !  -v stands for \"volume\". the  -v  option says to export the /tmp directory of the docker container\nto the /tmp directory of the host.\n18. we also export the /export directory of the container (any docker container has or\nshould have by default an /export directory) to an /export directory of the host (your VM here).  Note that if the /export directory does not exists at docker run runtime, it will be created.  So it is important to understand the -v magics: every directory specified by the -v option will be shared\nbetween the docker container filesystem and the host filesystem. It is a mapping operation, so that\nthe same directory is accessible either from inside the docker container or from inside the host.  Now, if you stop and remove the docker container, all exported directory will persist in the host.\nIf you don't do that, all operations performed with a container are lost when you stop this container !    This is the end of the docker run command. The docker image to be instantiated is specified.   reports to the terminal user  reports to the terminal user  reports to the terminal user  Now that the docker container is launched, you can access its logs with the command docker logs -f  (-f means continuous logging until keyboard interruption) followed by the\nidentification number of the docker container. We have put this ID in the variable  DOCKER_INSTANCE \nand we access to the content of this variable by prefixing the variable with a  $ : docker logs -f $DOCKER_INSTANCE", 
            "title": "The install_docker.sh script explained"
        }, 
        {
            "location": "/Google_cloud_Account/", 
            "text": "Run-Galaxy\n\n\nRun Galaxy training course\n\n\nGoogle Cloud Engine\n\n\n\n\nPrerequisite: a Google account / Gmail account\n\n\nConnect to \nGoogle Cloud Engine\n\n\nClick on \nEssai Gratuit\n / \nFree Trial\n\n\nEnter your Gmail mail address and password\n\n\nReview conditions and accept\n\n\nInscription Form:\n\n\nEntreprise\n / \nCompany\n : put anything like \"Perso\" or \"foo/bar\"\n\n\nAjouter une carte de paiement\n / \nAdd credit Card\n or optionally \nAjouter un compte bancaire\n / \nBank account\n\n\nYou are in for a free trial of 12 months / 300 $\n\n\ngo to your \nGoogle Cloud Console\n to control your spin off / control your Virtual Machines", 
            "title": "Appendix 1: Getting a Google Cloud Engine Account"
        }, 
        {
            "location": "/Google_cloud_Account/#run-galaxy", 
            "text": "", 
            "title": "Run-Galaxy"
        }, 
        {
            "location": "/Google_cloud_Account/#run-galaxy-training-course", 
            "text": "", 
            "title": "Run Galaxy training course"
        }, 
        {
            "location": "/Google_cloud_Account/#google-cloud-engine", 
            "text": "Prerequisite: a Google account / Gmail account  Connect to  Google Cloud Engine  Click on  Essai Gratuit  /  Free Trial  Enter your Gmail mail address and password  Review conditions and accept  Inscription Form:  Entreprise  /  Company  : put anything like \"Perso\" or \"foo/bar\"  Ajouter une carte de paiement  /  Add credit Card  or optionally  Ajouter un compte bancaire  /  Bank account  You are in for a free trial of 12 months / 300 $  go to your  Google Cloud Console  to control your spin off / control your Virtual Machines", 
            "title": "Google Cloud Engine"
        }, 
        {
            "location": "/spin_off_VM/", 
            "text": "Spin off a virtual Machine\n\n\n\n\nGo to the Google Cloud Dashboard and select \"Compute Engine\" on the left hand menu bar\n\n\n\n\nSelect the submenu \"Instances de VM\"\n\n\n\n\n\n\n\n\nClick on the top bar menu the \"CREER UNE INSTANCE\" panel\n\n\n\n\nPut name \"bare-galaxy\"\n\n\nChoose a Zone (suggestion: \neurope-west1-c\n)\n\n\nType de machine: choose 2 vCPU with 7.5 Memory\n\n\nDisque de D\u00e9marrage: Click on \nModifier\n\n\nSelect \nUbuntu 14.04 LTS\n\n\nAt the bottom of the form, put 100 Go for the Disk Size (Taille)\n\n\nLeave the selection \nDisque persistant standard\n / \nStandard persistant drive\n\n\nClick \nSelect\n / \nS\u00e9lectionner\n\n\n\n\n\n\nClick \nAuthorize HTTP traffic\n / \nAutoriser le traffic HTTP\n\n\n\n\nClick \nCr\u00e9er\n / \nCreate\n\n\nConnect to the started virtual Machine\n\n\nAfter a few seconds, the VM turns on \"green\" and an \nssh\n menu becomes selectable\n\n\n\n\n\n\n\n\nRoll down this \nssh\n menu and select the first option \nOuvrir dans la fen\u00eatre du navigateur\n\n\n\n\n\n\n\n\nA shell console pop out and you should now be ready to control your VM with linux command lines\n\n\n\n\n\n\n\n\n\n\nTry to enter the drosofff@bare-galaxy:~$ \nsudo -i\n command and hit the return key.\n\n\n\n\nThe unix prompt become \nroot@bare-galaxy:~#\n, you are mastering your VM as root administrator !\n\n\n[Optional] Here, if you do not have to work with the VM, you can turn off the VM and even trash it:\n\n\nin one shot, go back to your VM control panel in the web browser, ensure that the running VM is checked, and press the Trash button in the top menu.\n\n\nConfirm that you want to trash the VM and loose everything.\n\n\nafter a few seconds the VM disappears from the Dashboard.", 
            "title": "Appendix 1: Spin off a Virtual Machine"
        }, 
        {
            "location": "/spin_off_VM/#spin-off-a-virtual-machine", 
            "text": "Go to the Google Cloud Dashboard and select \"Compute Engine\" on the left hand menu bar   Select the submenu \"Instances de VM\"     Click on the top bar menu the \"CREER UNE INSTANCE\" panel   Put name \"bare-galaxy\"  Choose a Zone (suggestion:  europe-west1-c )  Type de machine: choose 2 vCPU with 7.5 Memory  Disque de D\u00e9marrage: Click on  Modifier  Select  Ubuntu 14.04 LTS  At the bottom of the form, put 100 Go for the Disk Size (Taille)  Leave the selection  Disque persistant standard  /  Standard persistant drive  Click  Select  /  S\u00e9lectionner    Click  Authorize HTTP traffic  /  Autoriser le traffic HTTP   Click  Cr\u00e9er  /  Create", 
            "title": "Spin off a virtual Machine"
        }, 
        {
            "location": "/spin_off_VM/#connect-to-the-started-virtual-machine", 
            "text": "After a few seconds, the VM turns on \"green\" and an  ssh  menu becomes selectable     Roll down this  ssh  menu and select the first option  Ouvrir dans la fen\u00eatre du navigateur     A shell console pop out and you should now be ready to control your VM with linux command lines      Try to enter the drosofff@bare-galaxy:~$  sudo -i  command and hit the return key.   The unix prompt become  root@bare-galaxy:~# , you are mastering your VM as root administrator !  [Optional] Here, if you do not have to work with the VM, you can turn off the VM and even trash it:  in one shot, go back to your VM control panel in the web browser, ensure that the running VM is checked, and press the Trash button in the top menu.  Confirm that you want to trash the VM and loose everything.  after a few seconds the VM disappears from the Dashboard.", 
            "title": "Connect to the started virtual Machine"
        }, 
        {
            "location": "/GCE_TP_Galaxy/", 
            "text": "Spin off a virtual Machine\n\n\n1. Go to the Google Cloud Dashboard and select \"Compute Engine\" on the left hand menu bar\n\n\n2. Select the submenu \"Instances de VM\"\n\n\n\n\n3. Click on the top bar menu the \"CREER UNE INSTANCE\" panel\n\n\n\n\n4. Put name \nmy-galaxy-server\n, Zone \neurope-west1-b (or c)\n, Type de machine \n8 vCPU\n + \n30 Go\n de m\u00e9moire.\n\n\n\n\n5. Disque de D\u00e9marrage: Click on \nModifier\n\n\n\n\n6. Select the top menu \nimages personnalis\u00e9es\n (\ncustom images\n)\n\n\n\n\n7. Click on the rolling menu \nAfficher les images de\n and select the \nMy Project - main-sunset-133416\n\n\n\n\nWhat is important here is the identifier \nmain-sunset-133416\n\n\n8. Check the button to select \ngalaxy-image-pasteur\n\n\n\n\n9. At the bottom of the same form, choose \n100 Go\n for the Disk Size (Taille). Note that this size should be already selected.\n\n\n\n\nClick the \nS\u00e9lectionner\n button to leave the selection \nDisque persistant standard\n / \nStandard persistant drive\n\n\n10. Back to the main form, Click \nAuthorize HTTP traffic\n / \nAutoriser le traffic HTTP\n\n\n\n\n11. Click \nCr\u00e9er\n / \nCreate\n\n\n12. After ~1 minute or so, the VM turns on \"green\" and an \nssh\n menu becomes selectable\n\n\n\n\n13. Click on the http link provided in the \nAdress IP externe\n column\n\n\nYou should now be able to access to your own Galaxy server instance, but not that this\nphase can take an additional minute or so, this is the time to start all the galaxy services\nin the new server instance.\n\n\n14. Immediately Log in to your server as the administrator\n\n\n\n\nAnd log in with \nadmin@galaxy.org\n : \nadmin\n\n\n\n\nYOU ARE READY TO USE GALAXY !", 
            "title": "Appendix 2: Run your personal TP Galaxy server"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#spin-off-a-virtual-machine", 
            "text": "", 
            "title": "Spin off a virtual Machine"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#1-go-to-the-google-cloud-dashboard-and-select-compute-engine-on-the-left-hand-menu-bar", 
            "text": "", 
            "title": "1. Go to the Google Cloud Dashboard and select \"Compute Engine\" on the left hand menu bar"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#2-select-the-submenu-instances-de-vm", 
            "text": "", 
            "title": "2. Select the submenu \"Instances de VM\""
        }, 
        {
            "location": "/GCE_TP_Galaxy/#3-click-on-the-top-bar-menu-the-creer-une-instance-panel", 
            "text": "", 
            "title": "3. Click on the top bar menu the \"CREER UNE INSTANCE\" panel"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#4-put-name-my-galaxy-server-zone-europe-west1-b-or-c-type-de-machine-8-vcpu-30-go-de-memoire", 
            "text": "", 
            "title": "4. Put name my-galaxy-server, Zone europe-west1-b (or c), Type de machine 8 vCPU + 30 Go de m\u00e9moire."
        }, 
        {
            "location": "/GCE_TP_Galaxy/#5-disque-de-demarrage-click-on-modifier", 
            "text": "", 
            "title": "5. Disque de D\u00e9marrage: Click on Modifier"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#6-select-the-top-menu-images-personnalisees-custom-images", 
            "text": "", 
            "title": "6. Select the top menu images personnalis\u00e9es (custom images)"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#7-click-on-the-rolling-menu-afficher-les-images-de-and-select-the-my-project-main-sunset-133416", 
            "text": "What is important here is the identifier  main-sunset-133416", 
            "title": "7. Click on the rolling menu Afficher les images de and select the My Project - main-sunset-133416"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#8-check-the-button-to-select-galaxy-image-pasteur", 
            "text": "", 
            "title": "8. Check the button to select galaxy-image-pasteur"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#9-at-the-bottom-of-the-same-form-choose-100-go-for-the-disk-size-taille-note-that-this-size-should-be-already-selected", 
            "text": "Click the  S\u00e9lectionner  button to leave the selection  Disque persistant standard  /  Standard persistant drive", 
            "title": "9. At the bottom of the same form, choose 100 Go for the Disk Size (Taille). Note that this size should be already selected."
        }, 
        {
            "location": "/GCE_TP_Galaxy/#10-back-to-the-main-form-click-authorize-http-traffic-autoriser-le-traffic-http", 
            "text": "", 
            "title": "10. Back to the main form, Click Authorize HTTP traffic / Autoriser le traffic HTTP"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#11-click-creer-create", 
            "text": "", 
            "title": "11. Click Cr\u00e9er / Create"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#12-after-1-minute-or-so-the-vm-turns-on-green-and-an-ssh-menu-becomes-selectable", 
            "text": "", 
            "title": "12. After ~1 minute or so, the VM turns on \"green\" and an ssh menu becomes selectable"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#13-click-on-the-http-link-provided-in-the-adress-ip-externe-column", 
            "text": "You should now be able to access to your own Galaxy server instance, but not that this\nphase can take an additional minute or so, this is the time to start all the galaxy services\nin the new server instance.", 
            "title": "13. Click on the http link provided in the Adress IP externe column"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#14-immediately-log-in-to-your-server-as-the-administrator", 
            "text": "And log in with  admin@galaxy.org  :  admin", 
            "title": "14. Immediately Log in to your server as the administrator"
        }, 
        {
            "location": "/GCE_TP_Galaxy/#you-are-ready-to-use-galaxy", 
            "text": "", 
            "title": "YOU ARE READY TO USE GALAXY !"
        }, 
        {
            "location": "/Galaxy_architecture/", 
            "text": "Galaxy software built", 
            "title": "Appendix 3: Galaxy software architecture"
        }, 
        {
            "location": "/Galaxy_architecture/#galaxy-software-built", 
            "text": "", 
            "title": "Galaxy software built"
        }, 
        {
            "location": "/mouse_genetics_command/", 
            "text": "Mouse Genetics Training: Command lines\n\n\nThe presentation file for \nDeep Seq Data Analysis: Theoretical training\n is available\nat the \nartbio\n website, \nhere\n.\n\n\nThe command lines used for the training are pasted below, by order of appearance.\n\n\nll\n\ngunzip GKG-13.fastq.gz\n\nll\n\nmore GKG-13.fastq\n\nwc -l  GKG-13.fastq\n\ngrep -c -e \n^@\n GKG-13.fastq\n\npython\n\ncat  GKG-13.fastq | grep CTGTAGG | wc -l\n\ngrep -c \nCTGTAGG\n GKG-13.fastq\n\ncat  GKG-13.fastq | grep ATCTCGT| wc -l\n\ncat GKG-13.fastq | perl -ne 'print if /^[ATGCN]{22}CTGTAGG/' | wc -l\n\ncat GKG-13.fastq | perl -ne 'if (/^(.+CTGTAGG)/) {print \n$1\\n\n}' | more\n\ncat GKG-13.fastq | perl -ne 'if (/^([GATC]{18,})CTGTAGG/) {$count++; print \n$count\\n\n; print \n$1\\n\n}' \n clipped_GKG13.fasta\n\nbowtie-build ../dmel/Dmel_r5.49.fa Dmel_r5.49\n\nbowtie ../dmel/Dmel_r5.49 -f clipped_GKG13.fasta -v 1 -k 1 -p 6 --al droso_matched_GKG-13.fa --un unmatched_GKG13.fa -S \n GKG13_bowtie_output.sam\n\nsamtools view -Sb GKG13_bowtie_output.sam \n GKG13_bowtie_output.bam\n\nsamtools view -Sb GKG13_bowtie_output.sam | samtools sort -@ 4 - GKG13_bowtie_output_sorted", 
            "title": "Mouse Genetics Theoritical Training (command lines)"
        }, 
        {
            "location": "/mouse_genetics_command/#mouse-genetics-training-command-lines", 
            "text": "The presentation file for  Deep Seq Data Analysis: Theoretical training  is available\nat the  artbio  website,  here .  The command lines used for the training are pasted below, by order of appearance.  ll\n\ngunzip GKG-13.fastq.gz\n\nll\n\nmore GKG-13.fastq\n\nwc -l  GKG-13.fastq\n\ngrep -c -e  ^@  GKG-13.fastq\n\npython\n\ncat  GKG-13.fastq | grep CTGTAGG | wc -l\n\ngrep -c  CTGTAGG  GKG-13.fastq\n\ncat  GKG-13.fastq | grep ATCTCGT| wc -l\n\ncat GKG-13.fastq | perl -ne 'print if /^[ATGCN]{22}CTGTAGG/' | wc -l\n\ncat GKG-13.fastq | perl -ne 'if (/^(.+CTGTAGG)/) {print  $1\\n }' | more\n\ncat GKG-13.fastq | perl -ne 'if (/^([GATC]{18,})CTGTAGG/) {$count++; print  $count\\n ; print  $1\\n }'   clipped_GKG13.fasta\n\nbowtie-build ../dmel/Dmel_r5.49.fa Dmel_r5.49\n\nbowtie ../dmel/Dmel_r5.49 -f clipped_GKG13.fasta -v 1 -k 1 -p 6 --al droso_matched_GKG-13.fa --un unmatched_GKG13.fa -S   GKG13_bowtie_output.sam\n\nsamtools view -Sb GKG13_bowtie_output.sam   GKG13_bowtie_output.bam\n\nsamtools view -Sb GKG13_bowtie_output.sam | samtools sort -@ 4 - GKG13_bowtie_output_sorted", 
            "title": "Mouse Genetics Training: Command lines"
        }
    ]
}